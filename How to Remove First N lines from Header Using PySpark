Prboblem:  Consider we have a report of web-page traffic generated everyday which contains the analytics 
           information such as session, pageviews, unique views etc.
           The sample report is shown in the figure given below. 
           To process the data and load into Spark DataFrame, we need to remove the first 7 lines from the file,
           as this data is not a relevant data (relevant SCHEMA).
           Our problem statement is how will you handle this sort of files and 
           how will you load the data into Spark DataFrame by removing first seven lines.
--------------------------------------------------------------------------------------------           
Input Data:

Site,www.learntospark.com
Desccription,"Complete guide to learn Spark,AI,ML"
Page Views of each blog
20200817-20200817

Total data in page,12

Page,Date,Pageviews,Unique_Pageviews,Sessions
Guide to Install Spark,2020-08-17,1140,986,800
Spark MAP vs FlatMap,2020-08-17,836,800,128
Spark Architechture,2020-08-17,1569,1345,1400
Azure Function for Mp3 to text,2020-08-17,350,245,234
Scala Vs Python,2020-08-17,200,150,130
Spark Window Function,2020-08-17,789,546,560
Natural Language Processing,2020-08-17,467,456,100
Spark Linear Interpolation - Time Series,2020-08-17,698,345,349
Spark case statement,2020-08-17,234,196,120
Spark Scenario Based Questions,2020-08-17,712,329,137
Spark v3.0 Delta Lake,2020-08-17,333,198,39
Screen Recorder App using Python,2020-08-17,766,567,344
Spark trick with Show(),2020-08-17,108,35,24
Spark Cache() Vs Persist,2020-08-17,587,432,300
Image Processing text to audio,2020-08-17,384,123,84
--------------------------------------------------------------------------------------------
InputFile download here : https://github.com/azar-s91/dataset/blob/master/pageview.csv
--------------------------------------------------------------------------------------------

PySpark Solution Code:

                        import findspark
                        findspark.init()

                        import pyspark
                        from pyspark import SparkContext
                        from pyspark.sql import SparkSession
                        from pyspark.sql import SQLContext
                        from pyspark.sql.functions import *
                        from pyspark.sql.types import *
                        #-------------Creating SparkSession & SparkSession------------
                        sc= SparkContext
                        spark = SparkSession.builder.getOrCreate()


                        #------------ Defining Schema --------------------------------

                        schema = StructType([StructField("Page", StringType(),True),
                                            StructField("Date", DateType(),True),
                                            StructField("Pageviews", IntegerType(),True),
                                            StructField("Unique_Pageviews", IntegerType(),True),
                                            StructField("Sessions", IntegerType(),True)])
                                            
                        #------------ Loading data into DataFrame with Defined Schema --------------------
                        df = spark.read.schema(schema).option('mode','DROPMALFORMED').csv("drop_n_columns.txt")
                        df.show()
 -----------------------------------------------------------------------------------------------------------------------------                   
 OutPut: 
 

 +--------------------+----------+---------+----------------+--------+
|                Page|      Date|Pageviews|Unique_Pageviews|Sessions|
+--------------------+----------+---------+----------------+--------+
|Guide to Install ...|2020-08-17|     1140|             986|     800|
|Spark MAP vs FlatMap|2020-08-17|      836|             800|     128|
| Spark Architechture|2020-08-17|     1569|            1345|    1400|
|Azure Function fo...|2020-08-17|      350|             245|     234|
|     Scala Vs Python|2020-08-17|      200|             150|     130|
|Spark Window Func...|2020-08-17|      789|             546|     560|
|Natural Language ...|2020-08-17|      467|             456|     100|
|Spark Linear Inte...|2020-08-17|      698|             345|     349|
|Spark case statement|2020-08-17|      234|             196|     120|
|Spark Scenario Ba...|2020-08-17|      712|             329|     137|
|Spark v3.0 Delta ...|2020-08-17|      333|             198|      39|
|Screen Recorder A...|2020-08-17|      766|             567|     344|
|Spark trick with ...|2020-08-17|      108|              35|      24|
|Spark Cache() Vs ...|2020-08-17|      587|             432|     300|
|Image Processing ...|2020-08-17|      384|             123|      84|
+--------------------+----------+---------+----------------+--------+



